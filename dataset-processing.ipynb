{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing dataset -- Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import json\n",
    "import pandas\n",
    "from chunkipy import TextChunker, TokenEstimator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/train.doj_guidance.jsonl.xz\"\n",
    "\n",
    "docs = []\n",
    "with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 100:\n",
    "            break\n",
    "        docs.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents.\")\n",
    "print(\"First document preview:\", docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the keys (fields) of the first document\n",
    "print(docs[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_and_save(text, chunk_size, tokens, overlap_percent, docId, output_dir=\"resources/data/chunks/guidance\"):\n",
    "    \"\"\"\n",
    "    Splits the input text into overlapping chunks and saves each chunk as a JSON file.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be chunked.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "        tokens (bool): Whether to chunk by tokens.\n",
    "        overlap_percent (float): Percentage of overlap between chunks.\n",
    "        document_name (str): Name of the original document.\n",
    "        output_dir (str): Directory to save the chunk files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    text_chunker = TextChunker(chunk_size, tokens=tokens, overlap_percent=overlap_percent)\n",
    "    chunks = text_chunker.chunk(text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_data = {\n",
    "            \"document_category\": \"guidance\", #change here\n",
    "            \"docId\": docId,\n",
    "            \"chunk_index\": i + 1,\n",
    "            \"chunk_text\": chunk\n",
    "        }\n",
    "        chunk_filename = f\"{docId}_chunk_{i + 1}.json\"\n",
    "        chunk_path = os.path.join(output_dir, chunk_filename)\n",
    "        with open(chunk_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(chunk_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Saved {chunk_filename} ({len(chunk)} chunk characters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over docs\n",
    "for idx, doc in enumerate(docs):\n",
    "    url = doc['url']\n",
    "    docId = \"guidance_\"+str(idx)\n",
    "    chunk_and_save(doc['text'], chunk_size=500, tokens=True, overlap_percent=0.1, docId=docId, output_dir= \"resources/data/chunks/guidance\")\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base_Folder = \"resources/data/querygen\"\n",
    "filenames = next(os.walk(base_Folder), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "\n",
    "chunks = []\n",
    "queries = []\n",
    "labels = []\n",
    "query_count = 0\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(base_Folder, filename), \"r\") as file:\n",
    "        chunks_batch = json.load(file)\n",
    "        for chunk in chunks_batch:\n",
    "            labels_chunk = []\n",
    "            chunk_queries = [q for q, s in zip(chunk[\"querygen\"], chunk[\"querygen_score\"]) if float(s) >= 1.5]\n",
    "            for chunk_query in chunk_queries:\n",
    "                queries.append({\"query_id\": query_count, \"query\": chunk_query})\n",
    "                labels_chunk.append({\"query_id\": query_count, \n",
    "                           \"doc_id\": chunk[\"doc_id\"],  \n",
    "                           \"chunk_id\": chunk[\"chunk_id\"],\n",
    "                           \"label\": \"Relevant\"})\n",
    "                query_count += 1\n",
    "            del chunk[\"querygen\"]\n",
    "            del chunk[\"querygen_score\"]\n",
    "            chunks.append(chunk)\n",
    "            labels.extend(labels_chunk)\n",
    "            \n",
    "            \n",
    "documents_df = pd.DataFrame(chunks)\n",
    "documents_df.rename(columns={\"document_category\": \"category\", \"text\": \"content\"}, inplace=True)\n",
    "documents_df.to_csv(\"dataset/legal-docs/document.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "queries_df = pd.DataFrame(queries)\n",
    "queries_df.set_index('query_id', inplace=True)\n",
    "queries_df.to_csv(\"dataset/legal-docs/query.csv\", index=True, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "labels_df.to_csv(\"dataset/legal-docs/positive-label.csv\", index=False, encoding=\"utf-8\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df = pd.read_csv(\"dataset/legal-docs/document.csv\")\n",
    "queries_df = pd.read_csv(\"dataset/legal-docs/query.csv\")\n",
    "positive_labels_df = pd.read_csv(\"dataset/legal-docs/positive-label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels_df[[\"doc_id\",\"chunk_id\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create negative labels\n",
    "\n",
    "import random\n",
    "from pyterrier_doc2query import QueryScorer\n",
    "from pyterrier_dr import ElectraScorer\n",
    "\n",
    "def create_negative_labels(labels_df, documents_df, quires_df, query_scorer):\n",
    "\n",
    "    query_id = labels_df[\"query_id\"].tolist()\n",
    "    random.shuffle(query_id)\n",
    "\n",
    "    # build df for Query Scorer\n",
    "    query_list = [{\n",
    "        \"query_id\": query_id[i],\n",
    "        \"doc_id\": labels_df['doc_id'][i],\n",
    "        \"chunk_id\": labels_df['chunk_id'][i],\n",
    "        \"text\": documents_df[documents_df[\"id\"] == f\"{labels_df['doc_id'][i]}__{labels_df['chunk_id'][i]}\"][\"content\"].values[0],\n",
    "        \"querygen\": quires_df[quires_df[\"query_id\"] == query_id[i]][\"query\"].values[0]\n",
    "    }\n",
    "    for i in range(len(labels_df))\n",
    "    ]\n",
    "\n",
    "    scores_df = query_scorer.transform(pd.DataFrame.from_records(query_list))\n",
    "\n",
    "    return scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 1\n",
    "\n",
    "negative_labels_df = pd.DataFrame()\n",
    "\n",
    "for _ in range(n_runs):\n",
    "     negative_labels_df = pd.concat((negative_labels_df,\n",
    "                                     create_negative_labels(positive_labels_df, documents_df, queries_df, QueryScorer(ElectraScorer()))\n",
    "                                     )\n",
    "                                    )\n",
    "negative_labels_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create relevance\n",
    "relevance = []\n",
    "for i in range(len(negative_labels_df)):\n",
    "    if negative_labels_df['querygen_score'][i][0] > 1.5:\n",
    "        relevance.append(\"Relevant\")\n",
    "    else:\n",
    "        relevance.append(\"Irrelevant\")\n",
    "\n",
    "\n",
    "negative_labels_df[\"label\"] = relevance\n",
    "negative_labels_df = negative_labels_df[positive_labels_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat with positive labels\n",
    "labels_df = pd.concat((positive_labels_df, negative_labels_df))\n",
    "labels_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.to_csv(\"dataset/legal-docs/label.csv\", index=False, encoding=\"utf-8\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
